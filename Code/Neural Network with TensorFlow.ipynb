{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "df = pd.read_csv(\"Three_Emoji_Simplified_root.csv\")\n",
    "test_df = pd.read_csv('test_set_root.csv')\n",
    "\n",
    "train_df = df.copy().iloc[:,2:].astype(float)\n",
    "test_df = test_df.copy().iloc[:,1:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_df.iloc[:,:-3].values\n",
    "y_train = train_df.iloc[:,-3:].values\n",
    "\n",
    "x_test = test_df.iloc[:,:-3].values\n",
    "y_test = test_df.iloc[:,-3:].values\n",
    "\n",
    "\n",
    "y_train_label = np.apply_along_axis(lambda x: np.where(x == 1), 1, y_train).squeeze()\n",
    "y_test_label = np.apply_along_axis(lambda x: np.where(x == 1), 1, y_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 85,\n",
       "         2.0: 227,\n",
       "         3.0: 364,\n",
       "         4.0: 371,\n",
       "         5.0: 363,\n",
       "         6.0: 349,\n",
       "         7.0: 319,\n",
       "         8.0: 309,\n",
       "         9.0: 301,\n",
       "         10.0: 247,\n",
       "         11.0: 259,\n",
       "         12.0: 224,\n",
       "         13.0: 186,\n",
       "         14.0: 107,\n",
       "         15.0: 74,\n",
       "         16.0: 51,\n",
       "         17.0: 20,\n",
       "         18.0: 2,\n",
       "         19.0: 9,\n",
       "         20.0: 5,\n",
       "         21.0: 4,\n",
       "         22.0: 1,\n",
       "         23.0: 1,\n",
       "         24.0: 1,\n",
       "         35.0: 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(test_df[:-3].sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_mask_2 = test_df[:-3].sum(1) > 7\n",
    "fil_df = test_df.copy().iloc[test_mask_2.values,:]\n",
    "x_test_fil = fil_df.iloc[:,:-3].values\n",
    "y_test_fil = fil_df.iloc[:,-3:].values\n",
    "\n",
    "y_test_fil_label = np.apply_along_axis(lambda x: np.where(x == 1), 1, y_test_fil).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, act_fun = None):\n",
    "    W = tf.Variable(tf.random_normal([in_size, out_size]),\n",
    "                   )\n",
    "    b = tf.Variable(tf.zeros([1, out_size]) + 0.1,\n",
    "                   )\n",
    "    z = tf.matmul(inputs, W) + b\n",
    "    \n",
    "    if act_fun == None:\n",
    "        outputs = z\n",
    "    else:\n",
    "        outputs = act_fun(z)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = data[idx]\n",
    "    labels_shuffle = labels[idx]\n",
    "    #labels_shuffle = np.asarray(labels_shuffle.values.reshape(len(labels_shuffle), 1))\n",
    "\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "xs = tf.placeholder(tf.float32, [None, x_train.shape[1]])\n",
    "ys = tf.placeholder(tf.float32, [None, y_train.shape[1]])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden layer\n",
    "l1 = tf.nn.dropout(add_layer(xs, x_train.shape[1], 10, act_fun = tf.nn.relu), keep_prob)\n",
    "#l1 = add_layer(xs, x_train.shape[1], 10, act_fun = tf.nn.relu)\n",
    "\n",
    "#hidden layer 2\n",
    "l2 = tf.nn.dropout(add_layer(l1, 10, 10, act_fun = tf.nn.relu), keep_prob)\n",
    "#l2 = add_layer(l1, 10, 10, act_fun = tf.nn.relu)\n",
    "\n",
    "#hidden layer 3\n",
    "l3 = tf.nn.dropout(add_layer(l2, 10, 10, act_fun = tf.nn.relu), keep_prob)\n",
    "\n",
    "l4 = tf.nn.dropout(add_layer(l3, 10, 10, act_fun = tf.nn.relu), keep_prob)\n",
    "\n",
    "l5 = add_layer(l4, 10, 10, act_fun = tf.nn.relu)\n",
    "\n",
    "#output layer\n",
    "y_hat = add_layer(l2, 10, 3, act_fun = tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss fun.\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels = ys,\n",
    "                                           logits = y_hat))\n",
    "\n",
    "# Define a optimizer\n",
    "train_step_adam = tf.train.AdamOptimizer(\n",
    "    learning_rate = 0.01).minimize(loss)\n",
    "\n",
    "# Convert logits to label indexed\n",
    "correct_pred = tf.argmax(y_hat, 1)\n",
    "\n",
    "# Define an accuracy matric\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration: 1\n",
      "Loss: 1.2076268\n",
      "\n",
      "Train Accuracy: 33.09568931805192 %\n",
      "Test Accuracy: 34.01775804661487 %\n",
      "\n",
      "At iteration: 1001\n",
      "Loss: 1.0979724\n",
      "\n",
      "At iteration: 2001\n",
      "Loss: 1.0836782\n",
      "\n",
      "Train Accuracy: 37.86361038414102 %\n",
      "Test Accuracy: 36.90344062153163 %\n",
      "\n",
      "At iteration: 3001\n",
      "Loss: 1.0551473\n",
      "\n",
      "At iteration: 4001\n",
      "Loss: 1.0316415\n",
      "\n",
      "Train Accuracy: 46.039767770658486 %\n",
      "Test Accuracy: 30.077691453940066 %\n",
      "\n",
      "At iteration: 5001\n",
      "Loss: 1.0232543\n",
      "\n",
      "At iteration: 6001\n",
      "Loss: 1.0159816\n",
      "\n",
      "Train Accuracy: 46.5661943867882 %\n",
      "Test Accuracy: 36.015538290788015 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "num_of_step = 20001\n",
    "\n",
    "for i in range(num_of_step):\n",
    "    x_batch, y_batch = next_batch(512, x_train, y_train)\n",
    "    \n",
    "    accuracy_val = sess.run([accuracy], feed_dict={xs:x_batch, ys:y_batch, keep_prob:1.0})\n",
    "    _ = sess.run([train_step_adam], feed_dict={xs:x_batch, ys:y_batch, keep_prob:0.5})\n",
    "    #_, accuracy_val = sess.run([train_step_adam, accuracy], \n",
    "    #            feed_dict={xs:x_batch, ys:y_batch, keep_prob:0.5})\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('At iteration: ' + str(i + 1))\n",
    "        print('Loss: ' + str(sess.run(loss, feed_dict={xs:x_train, ys:y_train,keep_prob:1.0})))\n",
    "        print('')\n",
    "    \n",
    "    \n",
    "    if i % 2000 == 0:\n",
    "        train_predicted = sess.run([correct_pred], \n",
    "                     feed_dict={xs: x_train,keep_prob:1.0})[0]\n",
    "        test_predicted = sess.run([correct_pred], \n",
    "                     feed_dict={xs: x_test_fil,keep_prob:1.0})[0]\n",
    "        train_outcome = (pd.get_dummies(train_predicted) == y_train)\n",
    "        test_outcome = (pd.get_dummies(test_predicted) == y_test_fil)\n",
    "        \n",
    "        train_accuracy = np.sum(train_outcome.apply(sum, axis=1) == 3) / len(y_train)\n",
    "        test_accuracy = np.sum(test_outcome.apply(sum, axis=1) == 3) / len(y_test_fil)\n",
    "\n",
    "        \n",
    "        print('Train Accuracy: ' + str(train_accuracy * 100) + ' %')\n",
    "        print('Test Accuracy: ' + str(test_accuracy * 100) + ' %') \n",
    "        print('')\n",
    "        \n",
    "    if (train_accuracy - test_accuracy) > 0.5:\n",
    "        #print('At epoch: ' + str(i + 1))\n",
    "        print('Diff. between over 30% -> Overfitting')\n",
    "        break\n",
    "        \n",
    "    if test_accuracy > 0.7:\n",
    "        #print('At epoch: ' + str(i + 1))\n",
    "        print('Test Accuracy reached ' + str(test_accuracy * 100) + ' %')\n",
    "        break\n",
    "    \n",
    "    #tf.confusion_matrix(y_test_fil, test_predicted)\n",
    "#sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 ... 2 0 0]\n",
      "Test Accuracy: 32.46392896781354 %\n"
     ]
    }
   ],
   "source": [
    "fitted = sess.run([correct_pred], \n",
    "                     feed_dict={xs: x_train})[0]\n",
    "predicted = sess.run([correct_pred], \n",
    "                     feed_dict={xs: x_test_fil})[0]\n",
    "\n",
    "#print(predicted)\n",
    "\n",
    "from __future__ import division\n",
    "outcome_train = pd.get_dummies(fitted) == y_train\n",
    "outcome_test = pd.get_dummies(predicted) == y_test_fil\n",
    "\n",
    "train_accuracy = np.sum(outcome_train.apply(sum, axis=1) == 3) / len(y_train)\n",
    "test_accuracy = np.sum(outcome_test.apply(sum, axis=1) == 3) / len(y_test_fil)\n",
    "\n",
    "print('Test Accuracy: ' + str(train_accuracy * 100) + ' %')\n",
    "print('Test Accuracy: ' + str(test_accuracy * 100) + ' %')\n",
    "\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Outcome: \n",
    "lr=0.01\n",
    "201 2 layer[in, 3, out]: 62.3%\n",
    "501 2 layer[in, 10, out]: 64.9%\n",
    "101 2 layer[in, 100, out]: 54.5%\n",
    "501 3 layer[in, 10, 10, out]: 68.39%\n",
    "501 3 layer[in, 20, 20, out]: 60.39%\n",
    "501 3 layer[in, 50, 50, out]: 55.70%\n",
    "101 3 layer[in, 100, 100, out]: 40.8% \n",
    "10001 3 layer[6603, 10, 10, 10, out]: 58.9 /33.22\n",
    "20001 3 layer[6603, 15, 15, out]: 62% /36%\n",
    "10001 3 layer[5587, 10, 10, 3] Adagrad: \n",
    "\n",
    "10001 3 layer[6603, 10, 10, 3], lr=0.05: 40%/30%\n",
    "\n",
    "batch size = 512\n",
    "10001 [5587, 10, 10, 3], 0.9 dropout: 61/32\n",
    "10001 [5587, 10, 10, 3], 0.5 dropout: 46/36 both increased smoothly\n",
    "10001 [5587, 10, 10, 10, 3], 0.5 dropout: 48/34 inc/ random \n",
    "\n",
    "batch size = 256\n",
    "10001 [5587, 10, 10, 3], 0.5 dropout:45, 32 inc/random\n",
    "\n",
    "當units數為50 ~ 100(lr 0.05)時，從500開始會被困在local optima\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataset = np.loadtxt('Three_Lable_Simplified_root.csv', delimiter=',',skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=, init='uniform', activation='relu'))\n",
    "model.add(Dense(5, init='uniform', activation='relu'))\n",
    "model.add(Dense(3, init='uniform', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          validation_data=(X_test, Y_test)\n",
    "          nb_epoch=100, batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "yukernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
